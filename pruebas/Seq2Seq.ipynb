{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "#import pandas\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificación por Posición#\n",
    "## $PE_{(pos,2i)}=\\sin(pos/10000^{2i/d_{model}})$<br/>$PE_{(pos,2i+1)}=\\cos(pos/10000^{2i/d_{model}})$ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cogerAngulo(pos, i, d):\n",
    "  ratiosAngulo = 1 / np.power(10000, (2 * (i//2)) / np.float32(d))\n",
    "  return pos * ratiosAngulo\n",
    "\n",
    "def codiciacionPosicional(posicion, d):\n",
    "  angulos = cogerAngulo(np.arange(posicion)[:, np.newaxis], np.arange(d)[np.newaxis, :], d)\n",
    "  \n",
    "  angulos[:, 0::2] = np.sin(angulos[:, 0::2]) #Lo hacemos para los pares\n",
    "  \n",
    "  angulos[:, 1::2] = np.cos(angulos[:, 1::2]) #Lo hacemos para los impares\n",
    "    \n",
    "  posCodificados = angulos[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(posCodificados, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mascaras ##\n",
    "útiles para despreciar palabras que pueden afectar al comportamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearMascaraEmpaquetada(secuencia):\n",
    "    secuencia=tf.cast(tf.math.equal(secuencia,0), tf.float32)\n",
    "    return secuencia[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def crearMascaraAlFrente(n): #Retorna una máscara diagonal de 0's en el triangulo inferior y de tamaño nxn\n",
    "    mascara=1-tf.linalg.band_part(tf.ones((n,n)),-1,0)\n",
    "    return mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATENCIÓN #\n",
    "## $Atencion(Q,K,V)=softmax_k(\\frac{QK^T}{(\\sqrt{d_k})})V$ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este método calcula el producto escalar de matrices con la ecuación de Atención\n",
    "def productoEscalarConAtencion(q,k,v, mascaraAtencion):\n",
    "    matrizQK=tf.matmul(q,k,transpose_b=True)\n",
    "    #Calculamos la profuncidad d\n",
    "    dk=tf.cast(tf.shape(k)[-1],tf.float32)\n",
    "    #Valor escalar de atención\n",
    "    atencionEscalar=matrizQK/tf.math.sqrt(dk)\n",
    "\n",
    "    #Sumamos la máscara de atención\n",
    "    if(mascaraAtencion is not None):\n",
    "        atencionEscalar+=(mascaraAtencion*-1e9) #el -1e9 es para generar un valor infinito.\n",
    "    \n",
    "    #Calculamos la función softmax y normalizamos al últmo eje\n",
    "    pesosAtencion=tf.nn.softmax(atencionEscalar, axis=-1)\n",
    "\n",
    "    salida=tf.matmul(pesosAtencion, v)\n",
    "\n",
    "    return salida, pesosAtencion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtencionMultiple(tf.keras.layers.Layer):\n",
    "  def __init__(self, d, numeroCabezas):\n",
    "    super(AtencionMultiple, self).__init__()\n",
    "    self.numeroCabezas = numeroCabezas\n",
    "    self.d = d\n",
    "    \n",
    "    assert d % self.numeroCabezas == 0\n",
    "    \n",
    "    self.profundida = d // self.numeroCabezas #División entera\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d)\n",
    "    self.wk = tf.keras.layers.Dense(d)\n",
    "    self.wv = tf.keras.layers.Dense(d)\n",
    "    \n",
    "    self.capaDensa = tf.keras.layers.Dense(d)\n",
    "\n",
    "  #  Divide la última dimensio dentro (numeroCabezas, profundidad) transponiendo el resultado\n",
    "  # que tiene dimensioines (tamañoPaque, numeroCabezas, longitudSecuencia, profundidad)\n",
    "  def dividirCabezas(self, x, tamañoPaquete):\n",
    "    x = tf.reshape(x, (tamañoPaquete, -1, self.numeroCabezas, self.profundida))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mascara):\n",
    "    tamañoPaquete = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)\n",
    "    k = self.wk(k) \n",
    "    v = self.wv(v)\n",
    "    \n",
    "    q = self.dividirCabezas(q, tamañoPaquete)\n",
    "    k = self.dividirCabezas(k, tamañoPaquete)\n",
    "    v = self.dividirCabezas(v, tamañoPaquete)\n",
    "    \n",
    "    resultadoAtencion, pesosAtencion = productoEscalarConAtencion(q, k, v, mascara)\n",
    "    \n",
    "    resultadoAtencion = tf.transpose(resultadoAtencion, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concatenarAtenciones = tf.reshape(resultadoAtencion, (tamañoPaquete, -1, self.d))\n",
    "\n",
    "    resultado = self.capaDensa(concatenarAtenciones)  \n",
    "        \n",
    "    return resultado, pesosAtencion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redNeuronalHaciaDelante(d, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapaCodificadora(tf.keras.layers.Layer):\n",
    "  def __init__(self, d, numeroCabezas, dff, ratio=0.1):\n",
    "    super(CapaCodificadora, self).__init__()\n",
    "\n",
    "    self.mCA = AtencionMultiple(d, numeroCabezas)\n",
    "    self.redFF = redNeuronalHaciaDelante(d, dff)\n",
    "\n",
    "    self.capaNormal1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.capaNormal2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.despreciar1 = tf.keras.layers.Dropout(ratio) \n",
    "    self.despreciar2 = tf.keras.layers.Dropout(ratio)\n",
    "    \n",
    "  def call(self, x, entrenamiento, mascara):\n",
    "\n",
    "    salidaAtencion, _ = self.mCA(x, x, x, mascara)\n",
    "    salidaAtencion = self.despreciar1(salidaAtencion, training=entrenamiento)\n",
    "    salida1 = self.capaNormal1(x + salidaAtencion)  \n",
    "    \n",
    "    salidaFFN = self.redFF(salida1)\n",
    "    salidaFFN = self.despreciar2(salidaFFN, training=entrenamiento)\n",
    "    salida2 = self.capaNormal2(salida1 + salidaFFN)  \n",
    "    \n",
    "    return salida2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapaDecodificadora(tf.keras.layers.Layer):\n",
    "    def __init__(self, d, numeroCabeceras, dff, ratio=0.1):\n",
    "        super(CapaDecodificadora, self).__init__()\n",
    "\n",
    "        self.mCA1=AtencionMultiple(d, numeroCabeceras)\n",
    "        self.mCA2=AtencionMultiple(d, numeroCabeceras)\n",
    "\n",
    "        self.redFF=redNeuronalHaciaDelante(d,dff)\n",
    "\n",
    "        self.capaNormal1=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.capaNormal2=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.capaNormal3=tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.despreciar1=tf.keras.layers.Dropout(ratio)\n",
    "        self.despreciar2=tf.keras.layers.Dropout(ratio)\n",
    "        self.despreciar3=tf.keras.layers.Dropout(ratio)\n",
    "\n",
    "    def call(self,x,salidaCodificada, entrenamiento, mascaraAlFrente, mascaraEmpaquetada):\n",
    "        atencion1, bloquePesosAtencion1 = self.mCA1(x,x,x,mascaraAlFrente)\n",
    "        atencion1=self.despreciar1(atencion1,training=entrenamiento)\n",
    "        salida1=self.capaNormal1(atencion1+x)\n",
    "        #print(salida1)\n",
    "        atencion2, bloquePesosAtencion2 = self.mCA2(salidaCodificada,salidaCodificada,salida1,mascaraEmpaquetada)\n",
    "        atencion2=self.despreciar2(atencion2,training=entrenamiento)\n",
    "        salida2=self.capaNormal2(atencion2+salida1)\n",
    "\n",
    "        salidaRedFF=self.redFF(salida2)\n",
    "        salidaRedFF=self.despreciar3(salidaRedFF, training=entrenamiento)\n",
    "        salida3=self.capaNormal3(salidaRedFF+salida2)\n",
    "\n",
    "        return salida3, bloquePesosAtencion1, bloquePesosAtencion2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Codificador(tf.keras.layers.Layer):\n",
    "    def __init__(self, numeroCapas, d, numeroCabeceras, dff, tamañoVocabulario, poisicionMaximaCodificacion, ratio=0.1):\n",
    "        super(Codificador, self).__init__()\n",
    "\n",
    "        self.d=d\n",
    "        self.numeroCapas=numeroCapas\n",
    "\n",
    "        self.embedding=tf.keras.layers.Embedding(tamañoVocabulario, d)\n",
    "        self.posicionesCodificadas=codiciacionPosicional(poisicionMaximaCodificacion, self.d)\n",
    "\n",
    "        self.capasCodificacion=[CapaCodificadora(d, numeroCabeceras,dff, ratio) for _ in range(self.numeroCapas)]\n",
    "\n",
    "        self.despreciar=tf.keras.layers.Dropout(ratio)\n",
    "\n",
    "    def call(self, x, entrenamiento, mascara):\n",
    "\n",
    "        longitudSecuencia=tf.shape(x)[1]\n",
    "\n",
    "        x=self.embedding(x)\n",
    "        x*=tf.math.sqrt(tf.cast(self.d,tf.float32))\n",
    "        x+=self.posicionesCodificadas[:, :longitudSecuencia, :]\n",
    "\n",
    "        x=self.despreciar(x, training=entrenamiento)\n",
    "\n",
    "        for i in range(self.numeroCapas):\n",
    "            x=self.capasCodificacion[i](x,entrenamiento,mascara)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decodificador(tf.keras.layers.Layer):\n",
    "    def __init__(self, numeroCapas, d, numeroCabeceras, dff, tamañoVocabulario, posicionMaximaCodificacion, ratio=0.1):\n",
    "        super(Decodificador, self).__init__()\n",
    "\n",
    "        self.d=d\n",
    "        self.numeroCapas=numeroCapas\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(tamañoVocabulario, d)\n",
    "        self.posicionesCodificadas=codiciacionPosicional(posicionMaximaCodificacion, d)\n",
    "\n",
    "        self.capasDecodificacion=[CapaDecodificadora(d, numeroCabeceras,dff, ratio) for _ in range(self.numeroCapas)]\n",
    "\n",
    "        self.despreciar=tf.keras.layers.Dropout(ratio)\n",
    "\n",
    "    def call(self, x, salidaCodificada, entrenamiento, mascaraAlFrente, mascaraEmpaquetada):\n",
    "\n",
    "        longitudSecuencia=tf.shape(x)[1]\n",
    "        pesosAtencion={}\n",
    "\n",
    "        x=self.embedding(x)\n",
    "        x*=tf.math.sqrt(tf.cast(self.d,tf.float32))\n",
    "        x+=self.posicionesCodificadas[:, :longitudSecuencia, :]\n",
    "\n",
    "        x=self.despreciar(x, training=entrenamiento)\n",
    "\n",
    "        for i in range(self.numeroCapas):\n",
    "            x, bloque1, bloque2 =self.capasDecodificacion[i](x,salidaCodificada,entrenamiento,mascaraAlFrente, mascaraEmpaquetada)\n",
    "\n",
    "            pesosAtencion['capaDecodificadora{}_bloque1'.format(i+1)]=bloque1\n",
    "            pesosAtencion['capaDecodificadora{}_bloque2'.format(i+1)]=bloque2\n",
    "\n",
    "        return x, pesosAtencion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, numeroCapas, d, numeroCabeceras, dff, tamañoVocabularioEntrada, \n",
    "               tamañoVocabularioSalida, posicionesEntrada, posicionesSalida, ratio=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.codificador = Codificador(numeroCapas, d, numeroCabeceras, dff, \n",
    "                           tamañoVocabularioEntrada, posicionesEntrada, ratio)\n",
    "\n",
    "    self.decodificador = Decodificador(numeroCapas, d, numeroCabeceras, dff, \n",
    "                           tamañoVocabularioSalida, posicionesSalida, ratio)\n",
    "\n",
    "    self.capaFinal = tf.keras.layers.Dense(tamañoVocabularioSalida)\n",
    "    \n",
    "  def call(self, entrada, objetivo, entrenamiento, mascaraCodificadaEmpaquetada, \n",
    "           mascaraAlFrente, mascaraDecodificadaEmpaquetada):\n",
    "\n",
    "    salidaCodificada = self.codificador(entrada, entrenamiento, mascaraCodificadaEmpaquetada)  \n",
    "    \n",
    "  \n",
    "    salidaDecodificada, pesosAtencion = self.decodificador(\n",
    "        objetivo, salidaCodificada, entrenamiento, mascaraAlFrente, mascaraDecodificadaEmpaquetada)\n",
    "    \n",
    "    salida = self.capaFinal(salidaDecodificada) \n",
    "    \n",
    "    return salida, pesosAtencion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los elementos de conversación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6172\n"
     ]
    }
   ],
   "source": [
    "diccionario=[]\n",
    "with open(\"./modelos/vocabulario_s2s.txt\",mode=\"r\",encoding=\"utf8\") as fichero:\n",
    "   for palabra in fichero:\n",
    "      diccionario.append(palabra[:-1])\n",
    "tamañoVocabulario=len(diccionario)\n",
    "print(len(diccionario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertarPalabra(palabra, palabras, posiciones, minuscula, palabrasInvalidas=[\"\\n\"]):\n",
    "    if len(palabra)==0 or palabra in palabrasInvalidas:\n",
    "        return\n",
    "    if minuscula:\n",
    "        palabra=palabra.lower()\n",
    "    if(palabra not in palabras):\n",
    "        palabras.append(palabra)\n",
    "    indice=palabras.index(palabra)\n",
    "    posiciones.append(indice)\n",
    "#Vocabulario obtiene tanto la lista de palabras como las posiciones por párrafo de cada palabra en el texto dado\n",
    "#juntarParrafos tiene en cuenta que un \\n que no está precedido por un \".\" o un \". \" no se considera como parrafo nuevo\n",
    "def vocabulario(linea, caracterSeparacion=' ', caracteresPuntuacion=['!','\"','#','$','%','&','(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\','\\'',']','^','_','`','{','|','}','~','\\t','\\n','\\r','¿','¡'], caracteresDescartados=['\\r', '\\t'], minuscula=True, palabras=['\\n'], conParrafos=False, juntarParrafos=False, caracteresFinalesParrafo=['.','_']):\n",
    "    posiciones=[]\n",
    "    parrafo=[]\n",
    "    esPuntuacion=False\n",
    "    palabra=\"\"\n",
    "    ultimoCaracter=\"\"\n",
    "    palabrasInvalidas=caracteresDescartados\n",
    "    for c in linea:\n",
    "        if(c==caracterSeparacion):\n",
    "            #if(esPuntuacion):\n",
    "            #    palabra+=c\n",
    "            insertarPalabra(palabra, palabras, parrafo, minuscula,palabrasInvalidas)\n",
    "            palabra=\"\"\n",
    "            esPuntuacion=False\n",
    "        else:\n",
    "            if(c not in caracteresPuntuacion):\n",
    "                if(esPuntuacion):\n",
    "                    insertarPalabra(palabra, palabras, parrafo,minuscula,palabrasInvalidas)\n",
    "                    esPuntuacion=False\n",
    "                    palabra=c\n",
    "                else:\n",
    "                    palabra+=c\n",
    "            else:\n",
    "                insertarPalabra(palabra, palabras, parrafo,minuscula,palabrasInvalidas)\n",
    "                palabra=\"\"\n",
    "                if c not in caracteresDescartados:\n",
    "                    palabra=c\n",
    "                    esPuntuacion=True\n",
    "        if c!=caracterSeparacion and c not in caracteresDescartados and c!='\\n':\n",
    "            ultimoCaracter=c\n",
    "    \n",
    "    if conParrafos and len(parrafo)>0:\n",
    "        if(not juntarParrafos or ultimoCaracter in caracteresFinalesParrafo):\n",
    "            posiciones.append(parrafo)\n",
    "            parrafo=[]\n",
    "    #TODO Implementar un mecanismo para evitar palabras cortadas al final de línea con el -\n",
    "    if palabra!=\"\":\n",
    "        insertarPalabra(palabra, palabras, parrafo,minuscula,palabrasInvalidas)\n",
    "        palabra=\"\"\n",
    "\n",
    "    if(len(parrafo)>0):\n",
    "        posiciones.append(parrafo)\n",
    "        parrafo=[]\n",
    "    return palabras,posiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cogerDiccionario(diccionario,conversaciones):\n",
    "    posicionesConversaciones=[]\n",
    "    for conversacion in conversaciones:\n",
    "        posicionesFrase=[]\n",
    "        for frase in conversacion:\n",
    "            diccionario,posiciones=vocabulario(frase.lower(),palabras=diccionario)\n",
    "            posicionesFrase.append(posiciones)\n",
    "        posicionesConversaciones.append(posicionesFrase)\n",
    "    return diccionario,posicionesConversaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(posiciones,tamaño):\n",
    "    #datos=[[longitud]+posiciones+[longitud+1]+[0]*(tamaño-len(posiciones)-2)]\n",
    "    datos=[1]+posiciones+[2]+[0]*(tamaño-len(posiciones))\n",
    "    #datos=posiciones+[0]*(tamaño-len(posiciones))\n",
    "\n",
    "    #datos=[posiciones]\n",
    "    #datos=posiciones+([0]*(tamaño-len(posiciones)))\n",
    "    #if(datos.shape[0]<tamaño):\n",
    "    #datos.set_shape([None])\n",
    "    return datos\n",
    "#normalizar(posiciones[0][0][0],40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera una salida con frases texto - respuesta\n",
    "def transformarConversacion(fichero):\n",
    "    textoAEntrenar=\"\"\n",
    "    conversaciones=[]\n",
    "    conversacion=[]\n",
    "    with open(fichero,mode=\"r\",encoding=\"utf8\") as fichero:\n",
    "        for linea in fichero:\n",
    "            if(linea[0]=='-'):\n",
    "                #Empezamos conversación\n",
    "                if(len(conversacion)>0):\n",
    "                    conversaciones.append(conversacion.copy())\n",
    "                    conversacion.clear()\n",
    "                linea=linea[1:]\n",
    "            frase=linea.strip()\n",
    "            if(len(frase)==0):\n",
    "                continue\n",
    "            if(frase[0]=='-'):\n",
    "                frase=frase[1:].strip()\n",
    "                conversacion.append(frase.strip('\"'))\n",
    "            else:\n",
    "                conversacion[len(conversacion)-1]+=\" \"+frase.strip()\n",
    "    if(len(conversacion)>0):\n",
    "        conversaciones.append(conversacion.copy())\n",
    "    return conversaciones\n",
    "def procesarSubtitulos(fichero, lineas=100, limitar=True):\n",
    "    conversacion=[]\n",
    "    frase=\"\"\n",
    "    with open(fichero,mode=\"r\",encoding=\"utf8\") as fichero:\n",
    "        iLinea=0\n",
    "        iParte=0\n",
    "        for linea in fichero:\n",
    "            if iLinea>lineas and limitar:\n",
    "               return conversacion\n",
    "            if iParte>=2:\n",
    "                if len(linea)==1:\n",
    "                    if frase[-3:]!=\"...\":\n",
    "                        if len(frase)>0:\n",
    "                            conversacion.append(frase)\n",
    "                            frase=\"\"\n",
    "                    else:\n",
    "                        frase=frase[0:-3]\n",
    "                    iParte=0\n",
    "                elif len(linea)>37:\n",
    "                    frase=linea[0:37]\n",
    "                else:\n",
    "                    linea=re.sub('<[^<]+?>', '', linea)\n",
    "                    if linea[0:3]==\"...\":\n",
    "                        linea=linea[3:]\n",
    "                    frase+=(\" \" if len(frase)>0 else \"\")+linea[0:-1].strip()\n",
    "                    #print(frase)\n",
    "                    iLinea+=1\n",
    "            else:\n",
    "                iParte+=1\n",
    "    if len(frase)>0:\n",
    "        conversacion.append(frase)\n",
    "        frase=\"\"\n",
    "    return conversacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ficheros=[\"textos/dialogo.txt\"]\n",
    "#diccionario=['\\n']\n",
    "posiciones=[]\n",
    "for fichero in ficheros:\n",
    "    conversaciones=transformarConversacion(fichero)\n",
    "    diccionario,posiciones=cogerDiccionario(diccionario,conversaciones)\n",
    "    #print(conversaciones[0],posiciones[0])\n",
    "    #print(len(diccionario),diccionario[0])\n",
    "tamañoVocabulario = len(diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "294 6173\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#subtitulos=os.scandir(\"/content/drive/My Drive/IA/BOT/textos/subtitulos\")\n",
    "\n",
    "subtitulos=os.scandir(\"textos/subtitulos2\")\n",
    "#subtitulos=[\"textos/subtitulos2/Futurama s01e03.srt\"]\n",
    "for fichero in subtitulos:\n",
    "    conversaciones =procesarSubtitulos(fichero, limitar=False)\n",
    "    diccionario,posiciones2=cogerDiccionario(diccionario,[conversaciones])\n",
    "    posiciones=posiciones+posiciones2\n",
    "tamañoVocabulario= len(diccionario) \n",
    "print(len(posiciones),len(diccionario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'franco'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "diccionario[6169]"
   ]
  },
  {
   "source": [
    "Crea paquetes de 64 lineas de entrada y salida y con líneas de almenos 48 palabras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#datosEntrenamiento=[]\n",
    "#for conversacion in posiciones:\n",
    "#    if(len(conversacion)>1):\n",
    "#        for i in range(len(conversacion)-1):\n",
    "#            datosEntrenamiento.append((tf.constant(normalizar(conversacion[i][0],tamañoVocabularioEntrada-2,48),tf.int64),tf.constant(normalizar(conversacion[i+1][0],#tamañoVocabularioEntrada-2,48),tf.int64)))\n",
    "#datosEntrenamiento[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datosEntrenamiento=[]\n",
    "entradaEntrenamiento=[]\n",
    "salidaEntrenamiento=[]\n",
    "for conversacion in posiciones:\n",
    "    if(len(conversacion)>1):\n",
    "        for i in range(len(conversacion)-1):\n",
    "            entradaEntrenamiento.append(tf.constant(normalizar(conversacion[i][0],48),tf.int64))\n",
    "            salidaEntrenamiento.append(tf.constant(normalizar(conversacion[i+1][0],48),tf.int64))\n",
    "entradaEntrenamiento=tf.data.Dataset.from_tensor_slices(entradaEntrenamiento)\n",
    "salidaEntrenamiento=tf.data.Dataset.from_tensor_slices(salidaEntrenamiento)\n",
    "\n",
    "datosEntrenamiento=tf.data.Dataset.zip((entradaEntrenamiento,salidaEntrenamiento))\n",
    "#datosEntrenamiento2 = datosEntrenamiento2.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "datosEntrenamiento = datosEntrenamiento.cache()\n",
    "datosEntrenamiento = datosEntrenamiento.shuffle(10000).padded_batch(64)\n",
    "datosEntrenamiento = datosEntrenamiento.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#print(next(iter(datosEntrenamiento)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(<tf.Tensor: shape=(64, 50), dtype=int64, numpy=\narray([[   1,  201, 2131, ...,    0,    0,    0],\n       [   1,   34,   20, ...,    0,    0,    0],\n       [   1,  193, 3959, ...,    0,    0,    0],\n       ...,\n       [   1,   84, 1922, ...,    0,    0,    0],\n       [   1,  482, 3382, ...,    0,    0,    0],\n       [   1,    6,   26, ...,    0,    0,    0]], dtype=int64)>, <tf.Tensor: shape=(64, 50), dtype=int64, numpy=\narray([[   1,    6,   34, ...,    0,    0,    0],\n       [   1,  422,   16, ...,    0,    0,    0],\n       [   1,  612,  458, ...,    0,    0,    0],\n       ...,\n       [   1,    6,   84, ...,    0,    0,    0],\n       [   1,  133, 3131, ...,    0,    0,    0],\n       [   1,   43,   16, ...,    0,    0,    0]], dtype=int64)>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(next(iter(datosEntrenamiento)))"
   ]
  },
  {
   "source": [
    "# Hiperparámetros #"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeroCapas = 4 #6\n",
    "d = 128 #512\n",
    "dff = 512 #2048\n",
    "numeroCabeceras = 8\n",
    "tamañoVocabulario = len(diccionario)\n",
    "ratioDespreciar = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar datos de entrenamiento ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizador #\n",
    "## $lrate=d^{-0.5}_{model}*\\min(step\\_num^{-0.5},step\\_num*warmup\\_steps^{-1.5})$ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramarOptimizacion(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d, pasosWarmup=4000):\n",
    "    super(ProgramarOptimizacion, self).__init__()\n",
    "    \n",
    "    self.d = d\n",
    "    self.d = tf.cast(self.d, tf.float32)\n",
    "\n",
    "    self.pasosWarmup = pasosWarmup\n",
    "    \n",
    "  def __call__(self, paso):\n",
    "    argumento1 = tf.math.rsqrt(paso)\n",
    "    argumento2 = paso * (self.pasosWarmup ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d) * tf.math.minimum(argumento1, argumento2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 405.564427 262.19625\" width=\"405.564427pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-12-24T09:24:43.973102</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 405.564427 262.19625 \r\nL 405.564427 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 62.86875 224.64 \r\nL 397.66875 224.64 \r\nL 397.66875 7.2 \r\nL 62.86875 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m82f05ff655\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.086932\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(74.905682 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.133338\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5000 -->\r\n      <g transform=\"translate(103.408338 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"154.179743\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10000 -->\r\n      <g transform=\"translate(138.273493 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.226149\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15000 -->\r\n      <g transform=\"translate(176.319899 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"230.272555\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20000 -->\r\n      <g transform=\"translate(214.366305 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.31896\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25000 -->\r\n      <g transform=\"translate(252.41271 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.365366\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30000 -->\r\n      <g transform=\"translate(290.459116 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.411772\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 35000 -->\r\n      <g transform=\"translate(328.505522 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"382.458177\" xlink:href=\"#m82f05ff655\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 40000 -->\r\n      <g transform=\"translate(366.551927 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_10\">\r\n     <!-- Train Step -->\r\n     <g transform=\"translate(205.300781 252.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M -0.296875 72.90625 \r\nL 61.375 72.90625 \r\nL 61.375 64.59375 \r\nL 35.5 64.59375 \r\nL 35.5 0 \r\nL 25.59375 0 \r\nL 25.59375 64.59375 \r\nL -0.296875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-84\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n       <path d=\"M 53.515625 70.515625 \r\nL 53.515625 60.890625 \r\nQ 47.90625 63.578125 42.921875 64.890625 \r\nQ 37.9375 66.21875 33.296875 66.21875 \r\nQ 25.25 66.21875 20.875 63.09375 \r\nQ 16.5 59.96875 16.5 54.203125 \r\nQ 16.5 49.359375 19.40625 46.890625 \r\nQ 22.3125 44.4375 30.421875 42.921875 \r\nL 36.375 41.703125 \r\nQ 47.40625 39.59375 52.65625 34.296875 \r\nQ 57.90625 29 57.90625 20.125 \r\nQ 57.90625 9.515625 50.796875 4.046875 \r\nQ 43.703125 -1.421875 29.984375 -1.421875 \r\nQ 24.8125 -1.421875 18.96875 -0.25 \r\nQ 13.140625 0.921875 6.890625 3.21875 \r\nL 6.890625 13.375 \r\nQ 12.890625 10.015625 18.65625 8.296875 \r\nQ 24.421875 6.59375 29.984375 6.59375 \r\nQ 38.421875 6.59375 43.015625 9.90625 \r\nQ 47.609375 13.234375 47.609375 19.390625 \r\nQ 47.609375 24.75 44.3125 27.78125 \r\nQ 41.015625 30.8125 33.5 32.328125 \r\nL 27.484375 33.5 \r\nQ 16.453125 35.6875 11.515625 40.375 \r\nQ 6.59375 45.0625 6.59375 53.421875 \r\nQ 6.59375 63.09375 13.40625 68.65625 \r\nQ 20.21875 74.21875 32.171875 74.21875 \r\nQ 37.3125 74.21875 42.625 73.28125 \r\nQ 47.953125 72.359375 53.515625 70.515625 \r\nz\r\n\" id=\"DejaVuSans-83\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-84\"/>\r\n      <use x=\"46.333984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"87.447266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"148.726562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"176.509766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"239.888672\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"271.675781\" xlink:href=\"#DejaVuSans-83\"/>\r\n      <use x=\"335.152344\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"374.361328\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"435.884766\" xlink:href=\"#DejaVuSans-112\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m86a3e0cf73\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"214.756364\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.0000 -->\r\n      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"186.467744\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.0002 -->\r\n      <g transform=\"translate(20.878125 190.266963)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"158.179125\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.0004 -->\r\n      <g transform=\"translate(20.878125 161.978344)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"129.890506\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.0006 -->\r\n      <g transform=\"translate(20.878125 133.689725)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"101.601887\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.0008 -->\r\n      <g transform=\"translate(20.878125 105.401105)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"73.313267\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 0.0010 -->\r\n      <g transform=\"translate(20.878125 77.112486)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"45.024648\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0.0012 -->\r\n      <g transform=\"translate(20.878125 48.823867)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.86875\" xlink:href=\"#m86a3e0cf73\" y=\"16.736029\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 0.0014 -->\r\n      <g transform=\"translate(20.878125 20.535248)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_19\">\r\n     <!-- Learning Rate -->\r\n     <g transform=\"translate(14.798438 150.679375)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n       <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n       <path d=\"M 44.390625 34.1875 \r\nQ 47.5625 33.109375 50.5625 29.59375 \r\nQ 53.5625 26.078125 56.59375 19.921875 \r\nL 66.609375 0 \r\nL 56 0 \r\nL 46.6875 18.703125 \r\nQ 43.0625 26.03125 39.671875 28.421875 \r\nQ 36.28125 30.8125 30.421875 30.8125 \r\nL 19.671875 30.8125 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nL 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.578125 72.90625 50.734375 67.671875 \r\nQ 56.890625 62.453125 56.890625 51.90625 \r\nQ 56.890625 45.015625 53.6875 40.46875 \r\nQ 50.484375 35.9375 44.390625 34.1875 \r\nz\r\nM 19.671875 64.796875 \r\nL 19.671875 38.921875 \r\nL 32.078125 38.921875 \r\nQ 39.203125 38.921875 42.84375 42.21875 \r\nQ 46.484375 45.515625 46.484375 51.90625 \r\nQ 46.484375 58.296875 42.84375 61.546875 \r\nQ 39.203125 64.796875 32.078125 64.796875 \r\nz\r\n\" id=\"DejaVuSans-82\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"115.486328\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"176.765625\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"216.128906\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"279.507812\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"307.291016\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"370.669922\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"434.146484\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"465.933594\" xlink:href=\"#DejaVuSans-82\"/>\r\n      <use x=\"533.166016\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"594.445312\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"633.654297\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#peecd9b4943)\" d=\"M 78.086932 214.756364 \r\nL 108.524056 17.083636 \r\nL 108.59254 17.305633 \r\nL 110.822059 24.148172 \r\nL 113.158109 30.60565 \r\nL 115.585469 36.665602 \r\nL 118.111751 42.377543 \r\nL 120.736953 47.766945 \r\nL 123.453466 52.84372 \r\nL 126.322165 57.732238 \r\nL 129.297394 62.361892 \r\nL 132.424808 66.812394 \r\nL 135.666362 71.037129 \r\nL 139.029664 75.059199 \r\nL 142.545152 78.922066 \r\nL 146.296528 82.710184 \r\nL 150.222917 86.354125 \r\nL 154.354757 89.880679 \r\nL 158.646391 93.252443 \r\nL 163.280443 96.603205 \r\nL 168.0819 99.798295 \r\nL 173.202946 102.935779 \r\nL 178.628364 105.994645 \r\nL 184.335324 108.955949 \r\nL 190.605372 111.946044 \r\nL 197.324367 114.884699 \r\nL 204.043363 117.584982 \r\nL 211.546114 120.355856 \r\nL 219.688045 123.110007 \r\nL 228.172393 125.73807 \r\nL 237.265484 128.318051 \r\nL 246.959708 130.835733 \r\nL 257.217019 133.273875 \r\nL 268.562457 135.737827 \r\nL 280.448154 138.093523 \r\nL 294.395967 140.606347 \r\nL 308.944912 142.98088 \r\nL 323.89715 145.198121 \r\nL 340.150574 147.389678 \r\nL 358.557425 149.637767 \r\nL 377.687158 151.751003 \r\nL 382.450568 152.24598 \r\nL 382.450568 152.24598 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 62.86875 224.64 \r\nL 62.86875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 397.66875 224.64 \r\nL 397.66875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 62.86875 224.64 \r\nL 397.66875 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 62.86875 7.2 \r\nL 397.66875 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"peecd9b4943\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"62.86875\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "ratioAprendizaje=ProgramarOptimizacion(d)\n",
    "optimizador=tf.keras.optimizers.Adam(ratioAprendizaje, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "ratioAprendizajeProgramadoTemporal=ProgramarOptimizacion(d)\n",
    "\n",
    "plt.plot(ratioAprendizajeProgramadoTemporal(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n",
    "\n",
    "#Text(0.5, 0, 'Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetoPerdido = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def funcionPerdida(real, predicho):\n",
    "  mascara = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  perdido = objetoPerdido(real, predicho)\n",
    "\n",
    "  mascara = tf.cast(mascara, dtype=perdido.dtype)\n",
    "  perdido *= mascara\n",
    "  \n",
    "  return tf.reduce_mean(perdido)/tf.reduce_sum(mascara)\n",
    "\n",
    "def funcionExactitud(real, prediccion):\n",
    "  exactitudes= tf.equal(real, tf.argmx(prediccion, axis=2))\n",
    "\n",
    "  mascara= tf.math.logical_not(tf.math.equal(real,0))\n",
    "  exactitudes= tf.math.logical_and(mascara, exactitudes)\n",
    "\n",
    "  exactitudes= tf.cast(exactitudes, dtype=tf.float32)\n",
    "  mascara=tf.cast(mascara, dtype=tf.float32)\n",
    "  return tf.reduce_sum(exactitudes)/tf.reduce_sum(mascara)\n",
    "\n",
    "def exactitud(real, prediccion):\n",
    "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "  real = tf.reshape(real, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(real, prediccion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamientoPerdidos = tf.keras.metrics.Mean(name='train_loss') #train_loss #entrenamientoPerdidos\n",
    "entrenamientoPrecision = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') # #entrenamientoPrecision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y puntos de control #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador = Transformer(numeroCapas, d, numeroCabeceras, dff,\n",
    "                          tamañoVocabulario, tamañoVocabulario, \n",
    "                          posicionesEntrada=tamañoVocabulario, posicionesSalida=tamañoVocabulario,\n",
    "                          ratio=ratioDespreciar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearMascara(entrada, salida):\n",
    "  mascaraCodificadaEmpaquetada = crearMascaraEmpaquetada(entrada)\n",
    "  mascaraDecodificadaEmpaquetada = crearMascaraEmpaquetada(entrada)\n",
    "  mascaraAlFrente = crearMascaraAlFrente(tf.shape(salida)[1])\n",
    "  mascaraDecodificadaEmpaqutadaObjetivo = crearMascaraEmpaquetada(salida)\n",
    "  \n",
    "  mascarasCombinadas = tf.maximum(mascaraDecodificadaEmpaqutadaObjetivo, mascaraAlFrente)\n",
    "  return mascaraCodificadaEmpaquetada, mascarasCombinadas, mascaraDecodificadaEmpaquetada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Restauramos el último punto de control\n"
     ]
    }
   ],
   "source": [
    "ficheroPuntoControl=\"./modelos/seq2seq/\"\n",
    "puntoControl=tf.train.Checkpoint(transformer=transformador, optimizer=optimizador)\n",
    "\n",
    "manejarPuntoControl=tf.train.CheckpointManager(puntoControl, ficheroPuntoControl, max_to_keep=5)\n",
    "\n",
    "if manejarPuntoControl.latest_checkpoint:\n",
    "  puntoControl.restore(manejarPuntoControl.latest_checkpoint)\n",
    "  print ('Restauramos el último punto de control')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "condicionesEntrenamiento = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "@tf.function(input_signature=condicionesEntrenamiento)\n",
    "def pasoEntrenamiento(entrada, objetivo):\n",
    "  entradaObjetivo = objetivo[:, :-1]\n",
    "  objetivoReal = objetivo[:, 1:]\n",
    "  #entradaObjetivo = objetivo\n",
    "  #objetivoReal = objetivo\n",
    "  #print(entradaObjetivo)\n",
    "  \n",
    "  mascaraCodificadaEmpaquetada, mascaraCombinada, mascaraDecodificadaEmpaquetada = crearMascara(entrada,entradaObjetivo)\n",
    "  #print(mascaraCodificadaEmpaquetada, mascaraCombinada, mascaraDecodificadaEmpaquetada)\n",
    "  \n",
    "  with tf.GradientTape() as cadenaEntrada:\n",
    "    #cadenaEntrada.watch(transformador.trainable_variables)\n",
    "    prediccion, _ = transformador(entrada, entradaObjetivo, \n",
    "                                 True, \n",
    "                                 mascaraCodificadaEmpaquetada, \n",
    "                                 mascaraCombinada, \n",
    "                                 mascaraDecodificadaEmpaquetada)\n",
    "    perdidas = funcionPerdida(objetivoReal, prediccion)\n",
    "    #print(perdidas)\n",
    "  #print(transformador.trainable_variables)\n",
    "  gradientes = cadenaEntrada.gradient(perdidas, transformador.trainable_variables)  \n",
    "  #print(list(zip(gradiente, transformador.trainable_variables))[1])  \n",
    "  optimizador.apply_gradients(zip(gradientes, transformador.trainable_variables))\n",
    "  \n",
    "  entrenamientoPerdidos(perdidas)\n",
    "  entrenamientoPrecision(objetivoReal,prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Transformer(numeroCapas, d, numeroCabeceras, dff,\n",
    "#                          tamañoVocabularioEntrada, tamañoVocabularioSalida, \n",
    "#                          posicionesEntrada=tamañoVocabularioEntrada, posicionesSalida=tamañoVocabularioSalida,\n",
    "#                          ratio=ratioDespreciar)\n",
    "#model.compile(optimizer=optimizador, loss=funcionPerdida, metrics=[exactitud])\n",
    "\n",
    "#EPOCHS = 20\n",
    "\n",
    "#model.fit(datosEntrenamiento, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perdida 0.0000 Precisión 0.1840\n",
      "Epoca 221 Lote 50 Perdida 0.0000 Precisión 0.1868\n",
      "Epoca 221 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.210962772369385 secs\n",
      "\n",
      "Epoca 222 Lote 0 Perdida 0.0000 Precisión 0.1907\n",
      "Epoca 222 Lote 50 Perdida 0.0000 Precisión 0.1895\n",
      "Epoca 222 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.099783897399902 secs\n",
      "\n",
      "Epoca 223 Lote 0 Perdida 0.0000 Precisión 0.1700\n",
      "Epoca 223 Lote 50 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 223 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.222052335739136 secs\n",
      "\n",
      "Epoca 224 Lote 0 Perdida 0.0000 Precisión 0.2079\n",
      "Epoca 224 Lote 50 Perdida 0.0000 Precisión 0.1889\n",
      "Epoca 224 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.135547161102295 secs\n",
      "\n",
      "Epoca 225 Lote 0 Perdida 0.0000 Precisión 0.1818\n",
      "Epoca 225 Lote 50 Perdida 0.0000 Precisión 0.1876\n",
      "Salvando punto de control en la epoca 225 a ./modelos/seq2seq/ckpt-123\n",
      "Epoca 225 Perdida 0.0000 Precisión 0.1870\n",
      "Tiempo que tomo desde la primera cada epoca: 11.488887786865234 secs\n",
      "\n",
      "Epoca 226 Lote 0 Perdida 0.0000 Precisión 0.1747\n",
      "Epoca 226 Lote 50 Perdida 0.0000 Precisión 0.1848\n",
      "Epoca 226 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.110125541687012 secs\n",
      "\n",
      "Epoca 227 Lote 0 Perdida 0.0000 Precisión 0.1916\n",
      "Epoca 227 Lote 50 Perdida 0.0000 Precisión 0.1883\n",
      "Epoca 227 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.105278968811035 secs\n",
      "\n",
      "Epoca 228 Lote 0 Perdida 0.0000 Precisión 0.1916\n",
      "Epoca 228 Lote 50 Perdida 0.0000 Precisión 0.1848\n",
      "Epoca 228 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.180792093276978 secs\n",
      "\n",
      "Epoca 229 Lote 0 Perdida 0.0000 Precisión 0.1958\n",
      "Epoca 229 Lote 50 Perdida 0.0000 Precisión 0.1867\n",
      "Epoca 229 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.13396692276001 secs\n",
      "\n",
      "Epoca 230 Lote 0 Perdida 0.0000 Precisión 0.1939\n",
      "Epoca 230 Lote 50 Perdida 0.0000 Precisión 0.1877\n",
      "Salvando punto de control en la epoca 230 a ./modelos/seq2seq/ckpt-124\n",
      "Epoca 230 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 12.082111358642578 secs\n",
      "\n",
      "Epoca 231 Lote 0 Perdida 0.0000 Precisión 0.1770\n",
      "Epoca 231 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Epoca 231 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.213730812072754 secs\n",
      "\n",
      "Epoca 232 Lote 0 Perdida 0.0000 Precisión 0.2057\n",
      "Epoca 232 Lote 50 Perdida 0.0000 Precisión 0.1881\n",
      "Epoca 232 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.106411695480347 secs\n",
      "\n",
      "Epoca 233 Lote 0 Perdida 0.0000 Precisión 0.1849\n",
      "Epoca 233 Lote 50 Perdida 0.0000 Precisión 0.1908\n",
      "Epoca 233 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.108922719955444 secs\n",
      "\n",
      "Epoca 234 Lote 0 Perdida 0.0000 Precisión 0.1783\n",
      "Epoca 234 Lote 50 Perdida 0.0000 Precisión 0.1856\n",
      "Epoca 234 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.122977495193481 secs\n",
      "\n",
      "Epoca 235 Lote 0 Perdida 0.0000 Precisión 0.1693\n",
      "Epoca 235 Lote 50 Perdida 0.0000 Precisión 0.1862\n",
      "Salvando punto de control en la epoca 235 a ./modelos/seq2seq/ckpt-125\n",
      "Epoca 235 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.569339990615845 secs\n",
      "\n",
      "Epoca 236 Lote 0 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 236 Lote 50 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 236 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.085835456848145 secs\n",
      "\n",
      "Epoca 237 Lote 0 Perdida 0.0000 Precisión 0.1916\n",
      "Epoca 237 Lote 50 Perdida 0.0000 Precisión 0.1864\n",
      "Epoca 237 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.117765665054321 secs\n",
      "\n",
      "Epoca 238 Lote 0 Perdida 0.0000 Precisión 0.1907\n",
      "Epoca 238 Lote 50 Perdida 0.0000 Precisión 0.1888\n",
      "Epoca 238 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.156818866729736 secs\n",
      "\n",
      "Epoca 239 Lote 0 Perdida 0.0000 Precisión 0.1875\n",
      "Epoca 239 Lote 50 Perdida 0.0000 Precisión 0.1870\n",
      "Epoca 239 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.30152702331543 secs\n",
      "\n",
      "Epoca 240 Lote 0 Perdida 0.0000 Precisión 0.1910\n",
      "Epoca 240 Lote 50 Perdida 0.0000 Precisión 0.1891\n",
      "Salvando punto de control en la epoca 240 a ./modelos/seq2seq/ckpt-126\n",
      "Epoca 240 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.671867370605469 secs\n",
      "\n",
      "Epoca 241 Lote 0 Perdida 0.0000 Precisión 0.1958\n",
      "Epoca 241 Lote 50 Perdida 0.0000 Precisión 0.1855\n",
      "Epoca 241 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.111035108566284 secs\n",
      "\n",
      "Epoca 242 Lote 0 Perdida 0.0000 Precisión 0.1757\n",
      "Epoca 242 Lote 50 Perdida 0.0000 Precisión 0.1884\n",
      "Epoca 242 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.073661804199219 secs\n",
      "\n",
      "Epoca 243 Lote 0 Perdida 0.0000 Precisión 0.1760\n",
      "Epoca 243 Lote 50 Perdida 0.0000 Precisión 0.1888\n",
      "Epoca 243 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.087412357330322 secs\n",
      "\n",
      "Epoca 244 Lote 0 Perdida 0.0000 Precisión 0.1834\n",
      "Epoca 244 Lote 50 Perdida 0.0000 Precisión 0.1861\n",
      "Epoca 244 Perdida 0.0000 Precisión 0.1871\n",
      "Tiempo que tomo desde la primera cada epoca: 11.113913297653198 secs\n",
      "\n",
      "Epoca 245 Lote 0 Perdida 0.0000 Precisión 0.1818\n",
      "Epoca 245 Lote 50 Perdida 0.0000 Precisión 0.1862\n",
      "Salvando punto de control en la epoca 245 a ./modelos/seq2seq/ckpt-127\n",
      "Epoca 245 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.581797361373901 secs\n",
      "\n",
      "Epoca 246 Lote 0 Perdida 0.0000 Precisión 0.1821\n",
      "Epoca 246 Lote 50 Perdida 0.0000 Precisión 0.1866\n",
      "Epoca 246 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.124295949935913 secs\n",
      "\n",
      "Epoca 247 Lote 0 Perdida 0.0000 Precisión 0.1773\n",
      "Epoca 247 Lote 50 Perdida 0.0000 Precisión 0.1852\n",
      "Epoca 247 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.151196718215942 secs\n",
      "\n",
      "Epoca 248 Lote 0 Perdida 0.0000 Precisión 0.2012\n",
      "Epoca 248 Lote 50 Perdida 0.0000 Precisión 0.1878\n",
      "Epoca 248 Perdida 0.0000 Precisión 0.1871\n",
      "Tiempo que tomo desde la primera cada epoca: 11.192265272140503 secs\n",
      "\n",
      "Epoca 249 Lote 0 Perdida 0.0000 Precisión 0.1757\n",
      "Epoca 249 Lote 50 Perdida 0.0000 Precisión 0.1870\n",
      "Epoca 249 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.15314531326294 secs\n",
      "\n",
      "Epoca 250 Lote 0 Perdida 0.0000 Precisión 0.1862\n",
      "Epoca 250 Lote 50 Perdida 0.0000 Precisión 0.1874\n",
      "Salvando punto de control en la epoca 250 a ./modelos/seq2seq/ckpt-128\n",
      "Epoca 250 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.629818439483643 secs\n",
      "\n",
      "Epoca 251 Lote 0 Perdida 0.0000 Precisión 0.1897\n",
      "Epoca 251 Lote 50 Perdida 0.0000 Precisión 0.1868\n",
      "Epoca 251 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.14879035949707 secs\n",
      "\n",
      "Epoca 252 Lote 0 Perdida 0.0000 Precisión 0.1805\n",
      "Epoca 252 Lote 50 Perdida 0.0000 Precisión 0.1884\n",
      "Epoca 252 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.120347261428833 secs\n",
      "\n",
      "Epoca 253 Lote 0 Perdida 0.0000 Precisión 0.1974\n",
      "Epoca 253 Lote 50 Perdida 0.0000 Precisión 0.1884\n",
      "Epoca 253 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.148660898208618 secs\n",
      "\n",
      "Epoca 254 Lote 0 Perdida 0.0000 Precisión 0.1735\n",
      "Epoca 254 Lote 50 Perdida 0.0000 Precisión 0.1861\n",
      "Epoca 254 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.097220659255981 secs\n",
      "\n",
      "Epoca 255 Lote 0 Perdida 0.0000 Precisión 0.1865\n",
      "Epoca 255 Lote 50 Perdida 0.0000 Precisión 0.1863\n",
      "Salvando punto de control en la epoca 255 a ./modelos/seq2seq/ckpt-129\n",
      "Epoca 255 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.595386266708374 secs\n",
      "\n",
      "Epoca 256 Lote 0 Perdida 0.0000 Precisión 0.1901\n",
      "Epoca 256 Lote 50 Perdida 0.0000 Precisión 0.1890\n",
      "Epoca 256 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.15855598449707 secs\n",
      "\n",
      "Epoca 257 Lote 0 Perdida 0.0000 Precisión 0.1840\n",
      "Epoca 257 Lote 50 Perdida 0.0000 Precisión 0.1898\n",
      "Epoca 257 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.098204612731934 secs\n",
      "\n",
      "Epoca 258 Lote 0 Perdida 0.0000 Precisión 0.1859\n",
      "Epoca 258 Lote 50 Perdida 0.0000 Precisión 0.1875\n",
      "Epoca 258 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.068290710449219 secs\n",
      "\n",
      "Epoca 259 Lote 0 Perdida 0.0000 Precisión 0.1798\n",
      "Epoca 259 Lote 50 Perdida 0.0000 Precisión 0.1873\n",
      "Epoca 259 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.111199617385864 secs\n",
      "\n",
      "Epoca 260 Lote 0 Perdida 0.0000 Precisión 0.1716\n",
      "Epoca 260 Lote 50 Perdida 0.0000 Precisión 0.1851\n",
      "Salvando punto de control en la epoca 260 a ./modelos/seq2seq/ckpt-130\n",
      "Epoca 260 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.698019742965698 secs\n",
      "\n",
      "Epoca 261 Lote 0 Perdida 0.0000 Precisión 0.1818\n",
      "Epoca 261 Lote 50 Perdida 0.0000 Precisión 0.1858\n",
      "Epoca 261 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.135630130767822 secs\n",
      "\n",
      "Epoca 262 Lote 0 Perdida 0.0000 Precisión 0.2012\n",
      "Epoca 262 Lote 50 Perdida 0.0000 Precisión 0.1881\n",
      "Epoca 262 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.124340057373047 secs\n",
      "\n",
      "Epoca 263 Lote 0 Perdida 0.0000 Precisión 0.1805\n",
      "Epoca 263 Lote 50 Perdida 0.0000 Precisión 0.1866\n",
      "Epoca 263 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.121788740158081 secs\n",
      "\n",
      "Epoca 264 Lote 0 Perdida 0.0000 Precisión 0.1830\n",
      "Epoca 264 Lote 50 Perdida 0.0000 Precisión 0.1872\n",
      "Epoca 264 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.17200779914856 secs\n",
      "\n",
      "Epoca 265 Lote 0 Perdida 0.0000 Precisión 0.1901\n",
      "Epoca 265 Lote 50 Perdida 0.0000 Precisión 0.1878\n",
      "Salvando punto de control en la epoca 265 a ./modelos/seq2seq/ckpt-131\n",
      "Epoca 265 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.49639081954956 secs\n",
      "\n",
      "Epoca 266 Lote 0 Perdida 0.0000 Precisión 0.1885\n",
      "Epoca 266 Lote 50 Perdida 0.0000 Precisión 0.1891\n",
      "Epoca 266 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.22490119934082 secs\n",
      "\n",
      "Epoca 267 Lote 0 Perdida 0.0000 Precisión 0.1853\n",
      "Epoca 267 Lote 50 Perdida 0.0000 Precisión 0.1851\n",
      "Epoca 267 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.133067607879639 secs\n",
      "\n",
      "Epoca 268 Lote 0 Perdida 0.0000 Precisión 0.1849\n",
      "Epoca 268 Lote 50 Perdida 0.0000 Precisión 0.1868\n",
      "Epoca 268 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.100741386413574 secs\n",
      "\n",
      "Epoca 269 Lote 0 Perdida 0.0000 Precisión 0.1948\n",
      "Epoca 269 Lote 50 Perdida 0.0000 Precisión 0.1861\n",
      "Epoca 269 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.100342273712158 secs\n",
      "\n",
      "Epoca 270 Lote 0 Perdida 0.0000 Precisión 0.1967\n",
      "Epoca 270 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Salvando punto de control en la epoca 270 a ./modelos/seq2seq/ckpt-132\n",
      "Epoca 270 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.550841331481934 secs\n",
      "\n",
      "Epoca 271 Lote 0 Perdida 0.0000 Precisión 0.1811\n",
      "Epoca 271 Lote 50 Perdida 0.0000 Precisión 0.1872\n",
      "Epoca 271 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.100817441940308 secs\n",
      "\n",
      "Epoca 272 Lote 0 Perdida 0.0000 Precisión 0.1859\n",
      "Epoca 272 Lote 50 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 272 Perdida 0.0000 Precisión 0.1872\n",
      "Tiempo que tomo desde la primera cada epoca: 11.111344575881958 secs\n",
      "\n",
      "Epoca 273 Lote 0 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 273 Lote 50 Perdida 0.0000 Precisión 0.1885\n",
      "Epoca 273 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.11471962928772 secs\n",
      "\n",
      "Epoca 274 Lote 0 Perdida 0.0000 Precisión 0.1837\n",
      "Epoca 274 Lote 50 Perdida 0.0000 Precisión 0.1880\n",
      "Epoca 274 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.143422842025757 secs\n",
      "\n",
      "Epoca 275 Lote 0 Perdida 0.0000 Precisión 0.1875\n",
      "Epoca 275 Lote 50 Perdida 0.0000 Precisión 0.1877\n",
      "Salvando punto de control en la epoca 275 a ./modelos/seq2seq/ckpt-133\n",
      "Epoca 275 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.706242561340332 secs\n",
      "\n",
      "Epoca 276 Lote 0 Perdida 0.0000 Precisión 0.1869\n",
      "Epoca 276 Lote 50 Perdida 0.0000 Precisión 0.1879\n",
      "Epoca 276 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.218406915664673 secs\n",
      "\n",
      "Epoca 277 Lote 0 Perdida 0.0000 Precisión 0.1818\n",
      "Epoca 277 Lote 50 Perdida 0.0000 Precisión 0.1886\n",
      "Epoca 277 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.289294719696045 secs\n",
      "\n",
      "Epoca 278 Lote 0 Perdida 0.0000 Precisión 0.1741\n",
      "Epoca 278 Lote 50 Perdida 0.0000 Precisión 0.1859\n",
      "Epoca 278 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.213284730911255 secs\n",
      "\n",
      "Epoca 279 Lote 0 Perdida 0.0000 Precisión 0.1827\n",
      "Epoca 279 Lote 50 Perdida 0.0000 Precisión 0.1878\n",
      "Epoca 279 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.196898221969604 secs\n",
      "\n",
      "Epoca 280 Lote 0 Perdida 0.0000 Precisión 0.2213\n",
      "Epoca 280 Lote 50 Perdida 0.0000 Precisión 0.1869\n",
      "Salvando punto de control en la epoca 280 a ./modelos/seq2seq/ckpt-134\n",
      "Epoca 280 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.66766619682312 secs\n",
      "\n",
      "Epoca 281 Lote 0 Perdida 0.0000 Precisión 0.1904\n",
      "Epoca 281 Lote 50 Perdida 0.0000 Precisión 0.1882\n",
      "Epoca 281 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.2317955493927 secs\n",
      "\n",
      "Epoca 282 Lote 0 Perdida 0.0000 Precisión 0.1671\n",
      "Epoca 282 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Epoca 282 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.255711078643799 secs\n",
      "\n",
      "Epoca 283 Lote 0 Perdida 0.0000 Precisión 0.1607\n",
      "Epoca 283 Lote 50 Perdida 0.0000 Precisión 0.1862\n",
      "Epoca 283 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.3190758228302 secs\n",
      "\n",
      "Epoca 284 Lote 0 Perdida 0.0000 Precisión 0.1792\n",
      "Epoca 284 Lote 50 Perdida 0.0000 Precisión 0.1884\n",
      "Epoca 284 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.247099876403809 secs\n",
      "\n",
      "Epoca 285 Lote 0 Perdida 0.0000 Precisión 0.1843\n",
      "Epoca 285 Lote 50 Perdida 0.0000 Precisión 0.1887\n",
      "Salvando punto de control en la epoca 285 a ./modelos/seq2seq/ckpt-135\n",
      "Epoca 285 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.711464881896973 secs\n",
      "\n",
      "Epoca 286 Lote 0 Perdida 0.0000 Precisión 0.1945\n",
      "Epoca 286 Lote 50 Perdida 0.0000 Precisión 0.1872\n",
      "Epoca 286 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.252202033996582 secs\n",
      "\n",
      "Epoca 287 Lote 0 Perdida 0.0000 Precisión 0.2038\n",
      "Epoca 287 Lote 50 Perdida 0.0000 Precisión 0.1881\n",
      "Epoca 287 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.553701877593994 secs\n",
      "\n",
      "Epoca 288 Lote 0 Perdida 0.0000 Precisión 0.2079\n",
      "Epoca 288 Lote 50 Perdida 0.0000 Precisión 0.1882\n",
      "Epoca 288 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.294789791107178 secs\n",
      "\n",
      "Epoca 289 Lote 0 Perdida 0.0000 Precisión 0.1865\n",
      "Epoca 289 Lote 50 Perdida 0.0000 Precisión 0.1888\n",
      "Epoca 289 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.144282817840576 secs\n",
      "\n",
      "Epoca 290 Lote 0 Perdida 0.0000 Precisión 0.1779\n",
      "Epoca 290 Lote 50 Perdida 0.0000 Precisión 0.1880\n",
      "Salvando punto de control en la epoca 290 a ./modelos/seq2seq/ckpt-136\n",
      "Epoca 290 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.62284541130066 secs\n",
      "\n",
      "Epoca 291 Lote 0 Perdida 0.0000 Precisión 0.1779\n",
      "Epoca 291 Lote 50 Perdida 0.0000 Precisión 0.1879\n",
      "Epoca 291 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.198736429214478 secs\n",
      "\n",
      "Epoca 292 Lote 0 Perdida 0.0000 Precisión 0.1894\n",
      "Epoca 292 Lote 50 Perdida 0.0000 Precisión 0.1874\n",
      "Epoca 292 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.104928493499756 secs\n",
      "\n",
      "Epoca 293 Lote 0 Perdida 0.0000 Precisión 0.1786\n",
      "Epoca 293 Lote 50 Perdida 0.0000 Precisión 0.1868\n",
      "Epoca 293 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.084684610366821 secs\n",
      "\n",
      "Epoca 294 Lote 0 Perdida 0.0000 Precisión 0.1776\n",
      "Epoca 294 Lote 50 Perdida 0.0000 Precisión 0.1858\n",
      "Epoca 294 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 10.993677377700806 secs\n",
      "\n",
      "Epoca 295 Lote 0 Perdida 0.0000 Precisión 0.1837\n",
      "Epoca 295 Lote 50 Perdida 0.0000 Precisión 0.1862\n",
      "Salvando punto de control en la epoca 295 a ./modelos/seq2seq/ckpt-137\n",
      "Epoca 295 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.981415748596191 secs\n",
      "\n",
      "Epoca 296 Lote 0 Perdida 0.0000 Precisión 0.1942\n",
      "Epoca 296 Lote 50 Perdida 0.0000 Precisión 0.1880\n",
      "Epoca 296 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.080136775970459 secs\n",
      "\n",
      "Epoca 297 Lote 0 Perdida 0.0000 Precisión 0.1789\n",
      "Epoca 297 Lote 50 Perdida 0.0000 Precisión 0.1892\n",
      "Epoca 297 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.04224181175232 secs\n",
      "\n",
      "Epoca 298 Lote 0 Perdida 0.0000 Precisión 0.1805\n",
      "Epoca 298 Lote 50 Perdida 0.0000 Precisión 0.1875\n",
      "Epoca 298 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.106418132781982 secs\n",
      "\n",
      "Epoca 299 Lote 0 Perdida 0.0000 Precisión 0.1818\n",
      "Epoca 299 Lote 50 Perdida 0.0000 Precisión 0.1887\n",
      "Epoca 299 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.289182662963867 secs\n",
      "\n",
      "Epoca 300 Lote 0 Perdida 0.0000 Precisión 0.1932\n",
      "Epoca 300 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Salvando punto de control en la epoca 300 a ./modelos/seq2seq/ckpt-138\n",
      "Epoca 300 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.592144250869751 secs\n",
      "\n",
      "Epoca 301 Lote 0 Perdida 0.0000 Precisión 0.2022\n",
      "Epoca 301 Lote 50 Perdida 0.0000 Precisión 0.1891\n",
      "Epoca 301 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.14639663696289 secs\n",
      "\n",
      "Epoca 302 Lote 0 Perdida 0.0000 Precisión 0.1983\n",
      "Epoca 302 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Epoca 302 Perdida 0.0000 Precisión 0.1874\n",
      "Tiempo que tomo desde la primera cada epoca: 11.021014213562012 secs\n",
      "\n",
      "Epoca 303 Lote 0 Perdida 0.0000 Precisión 0.2018\n",
      "Epoca 303 Lote 50 Perdida 0.0000 Precisión 0.1899\n",
      "Epoca 303 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.01936960220337 secs\n",
      "\n",
      "Epoca 304 Lote 0 Perdida 0.0000 Precisión 0.1958\n",
      "Epoca 304 Lote 50 Perdida 0.0000 Precisión 0.1872\n",
      "Epoca 304 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.108705520629883 secs\n",
      "\n",
      "Epoca 305 Lote 0 Perdida 0.0000 Precisión 0.2073\n",
      "Epoca 305 Lote 50 Perdida 0.0000 Precisión 0.1882\n",
      "Salvando punto de control en la epoca 305 a ./modelos/seq2seq/ckpt-139\n",
      "Epoca 305 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.496364831924438 secs\n",
      "\n",
      "Epoca 306 Lote 0 Perdida 0.0000 Precisión 0.1751\n",
      "Epoca 306 Lote 50 Perdida 0.0000 Precisión 0.1889\n",
      "Epoca 306 Perdida 0.0000 Precisión 0.1876\n",
      "Tiempo que tomo desde la primera cada epoca: 11.097327947616577 secs\n",
      "\n",
      "Epoca 307 Lote 0 Perdida 0.0000 Precisión 0.1894\n",
      "Epoca 307 Lote 50 Perdida 0.0000 Precisión 0.1877\n",
      "Epoca 307 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.083378314971924 secs\n",
      "\n",
      "Epoca 308 Lote 0 Perdida 0.0000 Precisión 0.1789\n",
      "Epoca 308 Lote 50 Perdida 0.0000 Precisión 0.1872\n",
      "Epoca 308 Perdida 0.0000 Precisión 0.1875\n",
      "Tiempo que tomo desde la primera cada epoca: 11.040191650390625 secs\n",
      "\n",
      "Epoca 309 Lote 0 Perdida 0.0000 Precisión 0.1843\n",
      "Epoca 309 Lote 50 Perdida 0.0000 Precisión 0.1860\n",
      "Epoca 309 Perdida 0.0000 Precisión 0.1873\n",
      "Tiempo que tomo desde la primera cada epoca: 11.300435066223145 secs\n",
      "\n",
      "Epoca 310 Lote 0 Perdida 0.0000 Precisión 0.1913\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-508174bed86f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[0mentrenamientoPrecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mentrada\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrespuesta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatosEntrenamiento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpasoEntrenamiento\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentrada\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrespuesta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m       print ('Epoca {} Lote {} Perdida {:.4f} Precisión {:.4f}'.format(\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCAS=500\n",
    "for epoca in range(EPOCAS):\n",
    "  tiempoInicial = time.time()\n",
    "  \n",
    "  entrenamientoPerdidos.reset_states()\n",
    "  entrenamientoPrecision.reset_states()\n",
    "  for (i, (entrada,respuesta)) in enumerate(datosEntrenamiento):\n",
    "    pasoEntrenamiento(entrada, respuesta)\n",
    "    if i % 50 == 0:\n",
    "      print ('Epoca {} Lote {} Perdida {:.4f} Precisión {:.4f}'.format(\n",
    "          epoca + 1, i, entrenamientoPerdidos.result(), entrenamientoPrecision.result()))\n",
    "      \n",
    "  if (epoca + 1) % 5 == 0:\n",
    "    puntoControlGuardado = manejarPuntoControl.save()\n",
    "    print ('Salvando punto de control en la epoca {} a {}'.format(epoca+1,\n",
    "                                                         puntoControlGuardado))\n",
    "    \n",
    "  print ('Epoca {} Perdida {:.4f} Precisión {:.4f}'.format(epoca + 1, \n",
    "                                                entrenamientoPerdidos.result(), entrenamientoPrecision.result()))\n",
    "\n",
    "  print ('Tiempo que tomo desde la primera cada epoca: {} secs\\n'.format(time.time() - tiempoInicial))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRUEBA ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(frase):\n",
    "    palabras=frase.split(\" \")\n",
    "    resultado=[]\n",
    "    for palabra in palabras:\n",
    "        palabra=palabra.lower()\n",
    "        if palabra in diccionario:\n",
    "            #diccionario.append(palabra)\n",
    "            resultado.append(diccionario.index(palabra))\n",
    "    #resultado.append(0)\n",
    "    return resultado\n",
    "def desTokenizar(entrada):\n",
    "    frase=\"\"\n",
    "    for e in entrada:\n",
    "        #print(e)\n",
    "        frase+=(\" \" if len(frase)>0 else \"\")+diccionario[e]\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respuesta(entrada):\n",
    "    # inp sentence is portuguese, hence adding the start and end token\n",
    "    entrada = tokenizar(entrada)\n",
    "    entrada = tf.expand_dims([1]+entrada+[2], 0)\n",
    "\n",
    "    print(entrada)\n",
    "  \n",
    "    salida = [1]\n",
    "    print(salida)\n",
    "    salida = tf.expand_dims(salida, 0)\n",
    "    print(salida)\n",
    "\n",
    "    for i in range(100):\n",
    "        mascaraCodificadaEmpaquetada, mascaraCombinada, mascaraDecodificadaEmpaquetada = crearMascara(entrada,salida)\n",
    "        prediccion, pesosAtencion = transformador(entrada, salida, False, mascaraCodificadaEmpaquetada, mascaraCombinada, mascaraDecodificadaEmpaquetada)\n",
    "        prediccion = prediccion[: ,-1:, :]\n",
    "        prediccionID=tf.cast(tf.argmax(prediccion, axis=-1), tf.int32)\n",
    "        #print(\"Pred\",prediccionID)\n",
    "        if tf.equal(prediccionID,2):\n",
    "            break\n",
    "        #print(prediccionID)\n",
    "        salida=tf.concat([salida,prediccionID], axis=-1)\n",
    "\n",
    "\n",
    "        #if predicted_id == tokenizer_en.vocab_size+1:\n",
    "        #    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "    return tf.squeeze(salida, axis=0), pesosAtencion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([[ 1 92  2]], shape=(1, 3), dtype=int32)\n",
      "[1]\n",
      "tf.Tensor([[1]], shape=(1, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[   1 1694    6   63   20 1742 1743    9    6  487   29   26  128   16\n",
      "   16   16    9], shape=(17,), dtype=int32)\n",
      "Input: ¿que te pasa?\n",
      "Predicted translation: < ¿ quién es esta persona ? ¿ estamos en lo cierto . . . ?\n"
     ]
    }
   ],
   "source": [
    "#entrada=\"Hola como estas\"\n",
    "entrada=\"¿que te pasa?\"\n",
    "#entrada=\"Eres una máquina\"\n",
    "resultado, pesos = respuesta(entrada)\n",
    "print(resultado)\n",
    "#respuestaPredicha = desTokenizar([i for i in resultado if i != 0])  \n",
    "respuestaPredicha = desTokenizar(resultado[1:])  \n",
    "print('Entrada: {}'.format(entrada))\n",
    "print('Respuesta: {}'.format(respuestaPredicha))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tamañoVocabularioEntrada\n",
    "def guardaDiccionario:\n",
    "    with open(\"modelos/vocabulario_s2s.txt\",mode=\"w\",encoding=\"utf8\") as fichero:\n",
    "        for palabra in diccionario:\n",
    "            fichero.write(palabra)\n",
    "    #diccionario\n",
    "    #np.savetxt(\"modelos/vocabulario_s2s.csv\",diccionario,delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-5450f5f46dd6>, line 2)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-5450f5f46dd6>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    tf.train.CheckpointManager.checkpoint.\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "len(diccionario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "icacion/2/capaNormal1/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal1/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal2/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/capaNormal3/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wk/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wq/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA1/wv/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wk/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wq/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/mCA2/wv/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-0/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/2/redFF/layer_with_weights-1/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal1/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal2/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/beta/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/gamma/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/capaNormal3/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wk/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wq/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA1/wv/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/capaDensa/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wk/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wq/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/mCA2/wv/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-0/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128, 512]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/bias/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/kernel/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/capasDecodificacion/3/redFF/layer_with_weights-1/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [512, 128]),\n",
       " ('transformer/decodificador/embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [6173, 128]),\n",
       " ('transformer/decodificador/embedding/embeddings/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [6173, 128]),\n",
       " ('transformer/decodificador/embedding/embeddings/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE',\n",
       "  [6173, 128])]"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "tf.train.list_variables(tf.train.latest_checkpoint(ficheroPuntoControl))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "05f650829d86801c43d76511a9c93696ceeffd2e765ad6e06f04450a4927f8c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}